{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Adaptive Meeting Notes Generator\n",
        "\n",
        "## Overview\n",
        "This Jupyter notebook provides a complete Proof of Concept (POC) for an Adaptive Meeting Notes Generator. It uses Generative AI to transform meeting transcripts into multi-layered summaries tailored for different audiences:\n",
        "- **Executives**: High-level insights.\n",
        "- **Teams**: Clear action items.\n",
        "- **Interns/Juniors**: Simplified recaps.\n",
        "\n",
        "Optional features include sentiment analysis or technical deep-dives. The solution leverages xAI's Grok API for AI processing.\n",
        "\n",
        "This notebook includes:\n",
        "- Detailed solution architecture and workflow.\n",
        "- Python code for the POC.\n",
        "- Sample execution and outputs.\n",
        "- Requirements for running the code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## System Architecture\n",
        "\n",
        "1. **Input Processing**\n",
        "   - **Source**: Meeting transcripts (text or audio converted to text via speech-to-text APIs like Whisper or Google Speech-to-Text).\n",
        "   - **Preprocessing**: Clean transcript (remove filler words, correct grammar, segment by speaker/topic).\n",
        "   - **Metadata**: User inputs for audience type (executive, team, junior) and optional flags for sentiment or technical analysis.\n",
        "\n",
        "2. **Generative AI Core**\n",
        "   - **Model**: A fine-tuned large language model (e.g., GPT-4, Llama, or xAI’s Grok) optimized for summarization and audience-specific tone.\n",
        "   - **Prompt Engineering**:\n",
        "     - **Executive Summary**: “Generate a concise, high-level summary of the meeting, focusing on strategic insights, key decisions, and outcomes in 100-150 words.”\n",
        "     - **Team Action Items**: “Extract and list clear, actionable tasks from the meeting transcript, assigning owners and deadlines where specified, in bullet-point format.”\n",
        "     - **Junior Recap**: “Create a simplified, plain-language summary of the meeting in 200-250 words, avoiding jargon and explaining key concepts.”\n",
        "     - **Sentiment Analysis (Optional)**: “Analyze the tone of the meeting (positive, neutral, negative) and highlight key emotional drivers or conflicts.”\n",
        "     - **Technical Deep-Dive (Optional)**: “Provide a detailed explanation of technical topics discussed, including diagrams or code snippets if relevant.”\n",
        "   - **Context Awareness**: The model uses metadata (e.g., meeting type, audience role) to adjust tone, depth, and focus.\n",
        "\n",
        "3. **Output Formatting**\n",
        "   - Outputs are generated in structured formats (e.g., JSON, Markdown) for easy integration into tools like Notion, Slack, or email.\n",
        "   - Example output structure:\n",
        "     ```json\n",
        "     {\n",
        "       \"executive_summary\": \"...\",\n",
        "       \"team_action_items\": [\"Task 1: ...\", \"Task 2: ...\"],\n",
        "       \"junior_recap\": \"...\",\n",
        "       \"sentiment_analysis\": {...},\n",
        "       \"technical_deep_dive\": \"...\"\n",
        "     }\n",
        "     ```\n",
        "\n",
        "4. **Integration Layer**\n",
        "   - **APIs**: Connects to meeting platforms (Zoom, Teams, Google Meet) for real-time transcript access.\n",
        "   - **Delivery**: Outputs delivered via email, Slack, or a web dashboard with role-based access (e.g., executives only see high-level summaries).\n",
        "   - **Customization**: Users can tweak summary length, tone, or focus via a configuration interface."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Workflow\n",
        "\n",
        "1. **Meeting Recording and Transcription**\n",
        "   - Audio/video from the meeting is captured via the meeting platform’s recording feature.\n",
        "   - Speech-to-text API converts audio to text in real time or post-meeting.\n",
        "\n",
        "2. **User Configuration**\n",
        "   - Users specify audience types (executive, team, junior) and optional analyses (sentiment, technical) via a web interface or meeting tool plugin.\n",
        "   - Example: A manager selects “Executive Summary + Team Action Items + Sentiment Analysis” for a project kickoff.\n",
        "\n",
        "3. **AI Processing**\n",
        "   - The transcript is segmented into topics using natural language processing (NLP) techniques (e.g., topic modeling with BERT).\n",
        "   - The Generative AI model processes the transcript based on the configured prompts, generating tailored outputs.\n",
        "   - Optional modules (sentiment, technical) are triggered if selected.\n",
        "\n",
        "4. **Output Delivery**\n",
        "   - Summaries are formatted and sent to designated recipients (e.g., executives get a PDF report, teams get Slack notifications with action items).\n",
        "   - Outputs are stored in a searchable database for future reference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Features\n",
        "\n",
        "- **Audience-Tailored Outputs**:\n",
        "  - **Executives**: 100-150 word strategic overview focusing on outcomes and decisions (e.g., “The team approved a $500K budget for Project X, targeting Q2 launch.”).\n",
        "  - **Teams**: Bullet-point action items with clear owners and deadlines (e.g., “- John: Finalize API specs by 10/10/2025. - Sarah: Schedule client demo for 10/15/2025.”).\n",
        "  - **Juniors**: Plain-language recap with explanations (e.g., “The meeting was about launching a new app. An API is like a bridge that lets different software talk to each other.”).\n",
        "  \n",
        "- **Optional Analyses**:\n",
        "  - **Sentiment Analysis**: Uses NLP to detect tone (e.g., “The meeting had a positive tone, with enthusiasm around the product launch, but mild tension over budget constraints.”).\n",
        "  - **Technical Deep-Dive**: Explains complex topics (e.g., “The discussion on microservices architecture involved splitting the app into smaller, independent components for scalability.”).\n",
        "\n",
        "- **Scalability**: Handles meetings of varying lengths and complexities, from 15-minute standups to multi-hour strategy sessions.\n",
        "- **Multilingual Support**: Processes transcripts in multiple languages using translation APIs (e.g., DeepL) for global teams.\n",
        "- **Privacy and Security**: Encrypts transcripts and summaries, with role-based access to ensure sensitive information is restricted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Technical Implementation\n",
        "\n",
        "1. **Tools and Technologies**:\n",
        "   - **Speech-to-Text**: OpenAI Whisper, Google Cloud Speech-to-Text, or AWS Transcribe.\n",
        "   - **Generative AI**: Fine-tuned Grok (xAI), GPT-4, or Llama for summarization and analysis.\n",
        "   - **NLP**: SpaCy or Hugging Face Transformers for topic segmentation and sentiment analysis.\n",
        "   - **APIs**: Zoom, Teams, or Google Meet APIs for transcript access; Slack/Email APIs for delivery.\n",
        "   - **Database**: PostgreSQL or MongoDB for storing transcripts and summaries.\n",
        "   - **Frontend**: React-based web dashboard for configuration and viewing outputs.\n",
        "   - **Backend**: Node.js or Python (FastAPI) for API orchestration.\n",
        "\n",
        "2. **Deployment**:\n",
        "   - Cloud-based (AWS, GCP, or Azure) for scalability.\n",
        "   - Serverless architecture (e.g., AWS Lambda) for cost-efficient processing of variable workloads.\n",
        "   - CI/CD pipeline for continuous updates to the AI model and features.\n",
        "\n",
        "3. **Fine-Tuning**:\n",
        "   - Train the AI model on a dataset of meeting transcripts and sample summaries to improve accuracy for specific industries (e.g., tech, finance).\n",
        "   - Use feedback loops (user ratings on summary quality) to refine outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## User Experience\n",
        "\n",
        "1. **Setup**:\n",
        "   - Users install a plugin or connect the tool to their meeting platform.\n",
        "   - They configure audience types and preferences in a simple UI (e.g., checkboxes for “Executive Summary,” “Sentiment Analysis”).\n",
        "\n",
        "2. **During/After Meeting**:\n",
        "   - The tool automatically processes the transcript post-meeting or in real time.\n",
        "   - Users receive tailored summaries within minutes, delivered to their preferred platform (e.g., Slack, email).\n",
        "\n",
        "3. **Example Outputs**:\n",
        "   - **Executive Summary**: “The Q3 planning meeting finalized a $1M marketing campaign targeting Gen Z, with a decision to prioritize TikTok ads. Next steps include vendor selection by Q4.”\n",
        "   - **Team Action Items**:\n",
        "     - “Marketing: Draft TikTok ad content by 10/12/2025 (Owner: Alice).”\n",
        "     - “Finance: Approve vendor budget by 10/15/2025 (Owner: Bob).”\n",
        "   - **Junior Recap**: “We talked about a new marketing plan to reach younger customers using TikTok. A campaign is like a big project to advertise our product. The team will pick a company to help us by next month.”\n",
        "   - **Sentiment Analysis**: “Positive sentiment overall, with excitement about TikTok strategy, but minor concerns about budget approval delays.”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Benefits\n",
        "\n",
        "- **Time Savings**: Eliminates manual note-taking and summarization, saving hours per meeting.\n",
        "- **Improved Alignment**: Ensures all team members, from interns to executives, understand outcomes relevant to their roles.\n",
        "- **Enhanced Clarity**: Simplifies complex discussions for juniors and focuses on action for teams.\n",
        "- **Flexibility**: Optional analyses provide deeper insights when needed.\n",
        "- **Scalability**: Works for small startups or large enterprises with global teams."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Challenges and Mitigations\n",
        "\n",
        "1. **Challenge**: Inaccurate transcripts (e.g., poor audio quality, accents).\n",
        "   - **Mitigation**: Use robust speech-to-text models and allow manual transcript correction via the dashboard.\n",
        "\n",
        "2. **Challenge**: Overly generic summaries.\n",
        "   - **Mitigation**: Fine-tune the AI model on industry-specific datasets and incorporate user feedback.\n",
        "\n",
        "3. **Challenge**: Privacy concerns with sensitive meeting data.\n",
        "   - **Mitigation**: Implement end-to-end encryption, anonymize sensitive data, and comply with GDPR/CCPA.\n",
        "\n",
        "4. **Challenge**: Handling diverse meeting formats (e.g., brainstorming vs. status updates).\n",
        "   - **Mitigation**: Use NLP to classify meeting type and adjust summarization logic accordingly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Future Enhancements\n",
        "\n",
        "- **Real-Time Summaries**: Generate drafts during the meeting for immediate review.\n",
        "- **Interactive Q&A**: Allow users to ask follow-up questions about the summary (e.g., “What was decided about the budget?”).\n",
        "- **Visualization**: Include auto-generated charts or diagrams for technical deep-dives.\n",
        "- **Voice Mode**: Integrate with Grok’s voice mode (available on iOS/Android) for verbal summaries.\n",
        "- **Custom Templates**: Let users define custom summary formats for specific roles or industries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Integration with xAI Products\n",
        "\n",
        "- **Grok**: Use Grok as the core Generative AI model for summarization and analysis, leveraging its ability to handle complex queries and adapt to user context.\n",
        "- **API**: Offer the solution as an API service via xAI’s API (https://x.ai/api) for integration into third-party platforms.\n",
        "- **SuperGrok**: Provide higher usage quotas for organizations via the SuperGrok subscription (details at https://x.ai/grok).\n",
        "- **Limitations**: BigBrain mode is not available, and pricing details for SuperGrok or API usage should be checked at https://x.ai/grok or https://x.ai/api."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## POC Code\n",
        "\n",
        "The following code demonstrates the core functionality using xAI's Grok API. Replace 'your_xai_api_key' with your actual API key.\n",
        "\n",
        "To run this in the notebook, ensure you have the required packages installed (see Requirements section below)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai==1.51.0\n",
            "  Downloading openai-1.51.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting anyio<5,>=3.5.0 (from openai==1.51.0)\n",
            "  Downloading anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting distro<2,>=1.7.0 (from openai==1.51.0)\n",
            "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting httpx<1,>=0.23.0 (from openai==1.51.0)\n",
            "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai==1.51.0)\n",
            "  Downloading jiter-0.11.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
            "Collecting pydantic<3,>=1.9.0 (from openai==1.51.0)\n",
            "  Downloading pydantic-2.11.10-py3-none-any.whl.metadata (68 kB)\n",
            "Collecting sniffio (from openai==1.51.0)\n",
            "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting tqdm>4 (from openai==1.51.0)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting typing-extensions<5,>=4.11 (from openai==1.51.0)\n",
            "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai==1.51.0)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting certifi (from httpx<1,>=0.23.0->openai==1.51.0)\n",
            "  Using cached certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai==1.51.0)\n",
            "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.51.0)\n",
            "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai==1.51.0)\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.33.2 (from pydantic<3,>=1.9.0->openai==1.51.0)\n",
            "  Downloading pydantic_core-2.33.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
            "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.9.0->openai==1.51.0)\n",
            "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Downloading openai-1.51.0-py3-none-any.whl (383 kB)\n",
            "Downloading anyio-4.11.0-py3-none-any.whl (109 kB)\n",
            "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
            "Downloading jiter-0.11.0-cp313-cp313-macosx_11_0_arm64.whl (314 kB)\n",
            "Downloading pydantic-2.11.10-py3-none-any.whl (444 kB)\n",
            "Downloading pydantic_core-2.33.2-cp313-cp313-macosx_11_0_arm64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
            "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
            "Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
            "Installing collected packages: typing-extensions, tqdm, sniffio, jiter, idna, h11, distro, certifi, annotated-types, typing-inspection, pydantic-core, httpcore, anyio, pydantic, httpx, openai\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/16\u001b[0m [openai]15/16\u001b[0m [openai]c]\n",
            "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 anyio-4.11.0 certifi-2025.8.3 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.10 jiter-0.11.0 openai-1.51.0 pydantic-2.11.10 pydantic-core-2.33.2 sniffio-1.3.1 tqdm-4.67.1 typing-extensions-4.15.0 typing-inspection-0.4.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install openai==1.51.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Client.__init__() got an unexpected keyword argument 'proxies'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Set your xAI API key and base URL\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m client = \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43myour_xai_api_key\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Replace with your actual xAI API key\u001b[39;49;00m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhttps://api.x.ai/v1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# xAI API base URL\u001b[39;49;00m\n\u001b[32m     17\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Sample meeting transcript (replace with real transcript as needed)\u001b[39;00m\n\u001b[32m     20\u001b[39m SAMPLE_TRANSCRIPT = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[33mSpeaker1: Good morning team. Today we\u001b[39m\u001b[33m'\u001b[39m\u001b[33mre discussing the Q3 product launch. We need to finalize the budget and assign tasks.\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[33mSpeaker2: I propose a $500K budget for marketing. John, can you handle the API development?\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     26\u001b[39m \u001b[33mSpeaker2: Agreed, let\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms aim for Q2 launch if possible.\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[33m\"\"\"\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/git/meeting-notes-tailor/.venv/lib/python3.13/site-packages/openai/_client.py:123\u001b[39m, in \u001b[36mOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m base_url \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    121\u001b[39m     base_url = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://api.openai.com/v1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m=\u001b[49m\u001b[43m__version__\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhttp_client\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_strict_response_validation\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_strict_response_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[38;5;28mself\u001b[39m._default_stream_cls = Stream\n\u001b[32m    136\u001b[39m \u001b[38;5;28mself\u001b[39m.completions = resources.Completions(\u001b[38;5;28mself\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/git/meeting-notes-tailor/.venv/lib/python3.13/site-packages/openai/_base_client.py:849\u001b[39m, in \u001b[36mSyncAPIClient.__init__\u001b[39m\u001b[34m(self, version, base_url, max_retries, timeout, transport, proxies, limits, http_client, custom_headers, custom_query, _strict_response_validation)\u001b[39m\n\u001b[32m    832\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    833\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid `http_client` argument; Expected an instance of `httpx.Client` but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(http_client)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    834\u001b[39m     )\n\u001b[32m    836\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m    837\u001b[39m     version=version,\n\u001b[32m    838\u001b[39m     limits=limits,\n\u001b[32m   (...)\u001b[39m\u001b[32m    847\u001b[39m     _strict_response_validation=_strict_response_validation,\n\u001b[32m    848\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m849\u001b[39m \u001b[38;5;28mself\u001b[39m._client = http_client \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mSyncHttpxClientWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    850\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    851\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# cast to a valid type because mypy doesn't understand our type narrowing\u001b[39;49;00m\n\u001b[32m    852\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    853\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    854\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    855\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlimits\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    857\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/git/meeting-notes-tailor/.venv/lib/python3.13/site-packages/openai/_base_client.py:747\u001b[39m, in \u001b[36m_DefaultHttpxClient.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    745\u001b[39m kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mlimits\u001b[39m\u001b[33m\"\u001b[39m, DEFAULT_CONNECTION_LIMITS)\n\u001b[32m    746\u001b[39m kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mfollow_redirects\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m747\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mTypeError\u001b[39m: Client.__init__() got an unexpected keyword argument 'proxies'"
          ]
        }
      ],
      "source": [
        "# Proof of Concept (POC) for Adaptive Meeting Notes Generator using xAI Grok API\n",
        "# This script demonstrates a basic implementation using xAI's Grok API for Generative AI.\n",
        "# It processes a sample meeting transcript and generates tailored summaries for different audiences.\n",
        "# Note: \n",
        "# 1. Create an xAI account and generate an API key at https://console.x.ai (or equivalent console).\n",
        "# 2. Replace 'your_xai_api_key' with your actual xAI API key.\n",
        "# 3. The xAI API is compatible with OpenAI's SDK. Install via pip: pip install openai\n",
        "# 4. For full documentation, visit https://docs.x.ai/docs/overview\n",
        "# 5. Models available: e.g., 'grok-4' (check latest at https://docs.x.ai/docs/models)\n",
        "\n",
        "import openai\n",
        "\n",
        "# Set your xAI API key and base URL\n",
        "client = openai.OpenAI(\n",
        "    api_key='your_xai_api_key',  # Replace with your actual xAI API key\n",
        "    base_url='https://api.x.ai/v1',  # xAI API base URL\n",
        ")\n",
        "\n",
        "# Sample meeting transcript (replace with real transcript as needed)\n",
        "SAMPLE_TRANSCRIPT = \"\"\"\n",
        "Speaker1: Good morning team. Today we're discussing the Q3 product launch. We need to finalize the budget and assign tasks.\n",
        "Speaker2: I propose a $500K budget for marketing. John, can you handle the API development?\n",
        "Speaker1: Yes, John will lead API specs by next Friday. Sarah, schedule the client demo for mid-October.\n",
        "Speaker3: I'm new here. What's an API?\n",
        "Speaker1: An API is like a bridge for software to communicate. Also, there was some tension on timelines, but overall positive vibe.\n",
        "Speaker2: Agreed, let's aim for Q2 launch if possible.\n",
        "\"\"\"\n",
        "\n",
        "# Prompts for different summary types\n",
        "PROMPTS = {\n",
        "    \"executive\": \"Generate a concise, high-level summary of the meeting transcript, focusing on strategic insights, key decisions, and outcomes in 100-150 words.\",\n",
        "    \"team\": \"Extract and list clear, actionable tasks from the meeting transcript, assigning owners and deadlines where specified, in bullet-point format.\",\n",
        "    \"junior\": \"Create a simplified, plain-language summary of the meeting transcript in 200-250 words, avoiding jargon and explaining key concepts.\",\n",
        "    \"sentiment\": \"Analyze the tone of the meeting transcript (positive, neutral, negative) and highlight key emotional drivers or conflicts.\",\n",
        "    \"technical\": \"Provide a detailed explanation of technical topics discussed in the meeting transcript, including examples if relevant.\"\n",
        "}\n",
        "\n",
        "def generate_summary(transcript, summary_type, optional=False, model='grok-beta'):\n",
        "    \"\"\"\n",
        "    Generate a specific type of summary using xAI Grok API.\n",
        "    \n",
        "    Args:\n",
        "    - transcript (str): The meeting transcript.\n",
        "    - summary_type (str): One of 'executive', 'team', 'junior', 'sentiment', 'technical'.\n",
        "    - optional (bool): If True, only generate if relevant (for sentiment/technical).\n",
        "    - model (str): The Grok model to use, e.g., 'grok-beta' or 'grok-4' (requires appropriate access).\n",
        "    \n",
        "    Returns:\n",
        "    - str: The generated summary.\n",
        "    \"\"\"\n",
        "    if summary_type not in PROMPTS:\n",
        "        raise ValueError(\"Invalid summary type.\")\n",
        "    \n",
        "    if optional and summary_type in [\"sentiment\", \"technical\"]:\n",
        "        # Simple check for relevance (in POC; improve with NLP in full version)\n",
        "        if summary_type == \"sentiment\" and \"tone\" not in transcript.lower():\n",
        "            return \"No sentiment analysis requested or relevant.\"\n",
        "        if summary_type == \"technical\" and \"api\" not in transcript.lower():\n",
        "            return \"No technical deep-dive relevant.\"\n",
        "    \n",
        "    prompt = f\"{PROMPTS[summary_type]}\\n\\nTranscript:\\n{transcript}\"\n",
        "    \n",
        "    response = client.chat.completions.create(\n",
        "        model=model,  # Use 'grok-4' if you have access; check https://docs.x.ai/docs/models for latest\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant for generating meeting summaries.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        max_tokens=300,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    \n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "# Example usage (uncomment to run)\n",
        "print(\"Generating Adaptive Meeting Notes POC using xAI Grok API...\\n\")\n",
        "executive_summary = generate_summary(SAMPLE_TRANSCRIPT, \"executive\")\n",
        "print(\"Executive Summary:\\n\", executive_summary, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Requirements\n",
        "\n",
        "To run the code, install the following dependencies:\n",
        "\n",
        "```plaintext\n",
        "# requirements.txt for Adaptive Meeting Notes Generator POC\n",
        "# These are the dependencies needed to run the script using xAI's Grok API\n",
        "# Install using: pip install -r requirements.txt\n",
        "\n",
        "# OpenAI SDK (used for xAI API compatibility)\n",
        "openai==1.51.0\n",
        "```\n",
        "\n",
        "### Notes:\n",
        "- The `openai` package is required because the xAI Grok API uses the OpenAI SDK for compatibility.\n",
        "- The version `1.51.0` is specified as a stable version at the time of writing (October 2025). You can update to the latest version by removing the version pin or checking for the latest via `pip install openai --upgrade`.\n",
        "- No additional dependencies are required for this POC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running the POC\n",
        "\n",
        "1. Install requirements: `!pip install -r requirements.txt` (or run in a code cell).\n",
        "2. Replace the API key in the code cell above.\n",
        "3. Uncomment and run the example usage lines to generate summaries from the sample transcript.\n",
        "\n",
        "For a full production system, extend this POC with speech-to-text integration, UI, and deployment."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
